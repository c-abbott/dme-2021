{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "documentary-stretch",
   "metadata": {},
   "source": [
    "In this lab we look at various unsupervised dimensionality reduction methods. By reducing the dimensionality to two or three dimensions only, we can visualise the data by e.g. scatter plots. Moreover, when we deal with labeled data, we may hope that in the low-dimensional space the classes are well-separated, that is, the transformed low-dimensional data form clusters which correspond to the different classes.\n",
    "\n",
    "As in Lab 1, we use the landsat satellite dataset which is 36-dimensional and comprises 6 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "biological-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get rid of possible future warnings cluttering the notebook\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Import required packages \n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn import manifold\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-national",
   "metadata": {},
   "source": [
    "# Preprocessing and initial visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-liquid",
   "metadata": {},
   "source": [
    "## Question 1: loading the data\n",
    "\n",
    "Load the `landsat_train.csv` dataset into a `pandas` DataFrame called  `landsat_train` and display the shape of the DataFrame. Moreover, load the label names stored in `landsat_classes.csv` into a single dictionary called `landsat_labels_dict` and print the names of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "modified-pittsburgh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4435, 37)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "landsat_train = pd.read_csv(\"../datasets/landsat/landsat_train.csv\")\n",
    "# 0 index labels to match Python dict convention\n",
    "landsat_train['label'] = landsat_train['label'].map(lambda label: label - 1) \n",
    "landsat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "floppy-arcade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>pixel_1_2</th>\n",
       "      <th>pixel_1_3</th>\n",
       "      <th>pixel_1_4</th>\n",
       "      <th>pixel_2_1</th>\n",
       "      <th>pixel_2_2</th>\n",
       "      <th>pixel_2_3</th>\n",
       "      <th>pixel_2_4</th>\n",
       "      <th>pixel_3_1</th>\n",
       "      <th>pixel_3_2</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_8_1</th>\n",
       "      <th>pixel_8_2</th>\n",
       "      <th>pixel_8_3</th>\n",
       "      <th>pixel_8_4</th>\n",
       "      <th>pixel_9_1</th>\n",
       "      <th>pixel_9_2</th>\n",
       "      <th>pixel_9_3</th>\n",
       "      <th>pixel_9_4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>115</td>\n",
       "      <td>120</td>\n",
       "      <td>94</td>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>106</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>88</td>\n",
       "      <td>121</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>107</td>\n",
       "      <td>113</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>106</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>107</td>\n",
       "      <td>113</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>94</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "      <td>94</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>94</td>\n",
       "      <td>98</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>107</td>\n",
       "      <td>109</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>56</td>\n",
       "      <td>64</td>\n",
       "      <td>108</td>\n",
       "      <td>96</td>\n",
       "      <td>64</td>\n",
       "      <td>71</td>\n",
       "      <td>108</td>\n",
       "      <td>96</td>\n",
       "      <td>68</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>66</td>\n",
       "      <td>83</td>\n",
       "      <td>108</td>\n",
       "      <td>96</td>\n",
       "      <td>66</td>\n",
       "      <td>87</td>\n",
       "      <td>104</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>64</td>\n",
       "      <td>71</td>\n",
       "      <td>108</td>\n",
       "      <td>96</td>\n",
       "      <td>68</td>\n",
       "      <td>75</td>\n",
       "      <td>108</td>\n",
       "      <td>96</td>\n",
       "      <td>71</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>66</td>\n",
       "      <td>87</td>\n",
       "      <td>104</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>104</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>68</td>\n",
       "      <td>75</td>\n",
       "      <td>108</td>\n",
       "      <td>96</td>\n",
       "      <td>71</td>\n",
       "      <td>87</td>\n",
       "      <td>108</td>\n",
       "      <td>88</td>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>104</td>\n",
       "      <td>89</td>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "      <td>104</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>71</td>\n",
       "      <td>87</td>\n",
       "      <td>108</td>\n",
       "      <td>88</td>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "      <td>104</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>91</td>\n",
       "      <td>104</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>95</td>\n",
       "      <td>108</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>91</td>\n",
       "      <td>104</td>\n",
       "      <td>85</td>\n",
       "      <td>63</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4435 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_1_1  pixel_1_2  pixel_1_3  pixel_1_4  pixel_2_1  pixel_2_2  \\\n",
       "0            92        115        120         94         84        102   \n",
       "1            84        102        106         79         84        102   \n",
       "2            84        102        102         83         80        102   \n",
       "3            80        102        102         79         84         94   \n",
       "4            84         94        102         79         80         94   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4430         56         64        108         96         64         71   \n",
       "4431         64         71        108         96         68         75   \n",
       "4432         68         75        108         96         71         87   \n",
       "4433         71         87        108         88         71         91   \n",
       "4434         71         91        100         81         76         95   \n",
       "\n",
       "      pixel_2_3  pixel_2_4  pixel_3_1  pixel_3_2  ...  pixel_7_4  pixel_8_1  \\\n",
       "0           106         79         84        102  ...        104         88   \n",
       "1           102         83         80        102  ...        100         84   \n",
       "2           102         79         84         94  ...         87         84   \n",
       "3           102         79         80         94  ...         79         84   \n",
       "4            98         76         80        102  ...         79         84   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "4430        108         96         68         75  ...         92         66   \n",
       "4431        108         96         71         87  ...         96         66   \n",
       "4432        108         88         71         91  ...         89         63   \n",
       "4433        100         81         76         95  ...         89         70   \n",
       "4434        108         88         80         95  ...         85         70   \n",
       "\n",
       "      pixel_8_2  pixel_8_3  pixel_8_4  pixel_9_1  pixel_9_2  pixel_9_3  \\\n",
       "0           121        128        100         84        107        113   \n",
       "1           107        113         87         84         99        104   \n",
       "2            99        104         79         84         99        104   \n",
       "3            99        104         79         84        103        104   \n",
       "4           103        104         79         79        107        109   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4430         83        108         96         66         87        104   \n",
       "4431         87        104         89         63         87        104   \n",
       "4432         87        104         89         70        100        104   \n",
       "4433        100        104         85         70         91        104   \n",
       "4434         91        104         85         63         91        100   \n",
       "\n",
       "      pixel_9_4  label  \n",
       "0            87      2  \n",
       "1            79      2  \n",
       "2            79      2  \n",
       "3            79      2  \n",
       "4            87      2  \n",
       "...         ...    ...  \n",
       "4430         89      4  \n",
       "4431         89      4  \n",
       "4432         85      3  \n",
       "4433         85      3  \n",
       "4434         81      3  \n",
       "\n",
       "[4435 rows x 37 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landsat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fatty-directory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'red soil',\n",
       " 1: 'cotton crop',\n",
       " 2: 'grey soil',\n",
       " 3: 'damp grey soil',\n",
       " 4: 'soil with vegetation stubble',\n",
       " 5: 'mixture class (all types present)',\n",
       " 6: 'very damp grey soil'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manipulate landsat_classes csv into Python dict\n",
    "landsat_classes = pd.read_csv(\"../datasets/landsat/landsat_classes.csv\")\n",
    "landsat_classes = landsat_classes.to_dict()\n",
    "landsat_classes.pop(\"Unnamed: 0\")\n",
    "landsat_labels_dict = landsat_classes[\"Class\"]\n",
    "landsat_labels_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-melbourne",
   "metadata": {},
   "source": [
    "Now we want to replace the label numbers in the `landsat_train` DataFrame with the corresponding class names. We can achieve that by using the `pandas` function `replace()`. The `inplace` argument determines whether the method alters the object it is called upon and returns nothing, or returns a new object (when `inplace` is set to `False`).  \n",
    "\n",
    "Execute the cell below which performs this replacement. The second line is used to show a random sample of 5 entries of the DataFrame for us to inspect the outcome of this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "french-knitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>pixel_1_2</th>\n",
       "      <th>pixel_1_3</th>\n",
       "      <th>pixel_1_4</th>\n",
       "      <th>pixel_2_1</th>\n",
       "      <th>pixel_2_2</th>\n",
       "      <th>pixel_2_3</th>\n",
       "      <th>pixel_2_4</th>\n",
       "      <th>pixel_3_1</th>\n",
       "      <th>pixel_3_2</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_8_1</th>\n",
       "      <th>pixel_8_2</th>\n",
       "      <th>pixel_8_3</th>\n",
       "      <th>pixel_8_4</th>\n",
       "      <th>pixel_9_1</th>\n",
       "      <th>pixel_9_2</th>\n",
       "      <th>pixel_9_3</th>\n",
       "      <th>pixel_9_4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>67</td>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "      <td>64</td>\n",
       "      <td>67</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>64</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>65</td>\n",
       "      <td>72</td>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "      <td>68</td>\n",
       "      <td>very damp grey soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>80</td>\n",
       "      <td>94</td>\n",
       "      <td>102</td>\n",
       "      <td>83</td>\n",
       "      <td>76</td>\n",
       "      <td>89</td>\n",
       "      <td>98</td>\n",
       "      <td>79</td>\n",
       "      <td>68</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>79</td>\n",
       "      <td>91</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>75</td>\n",
       "      <td>79</td>\n",
       "      <td>96</td>\n",
       "      <td>79</td>\n",
       "      <td>soil with vegetation stubble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>46</td>\n",
       "      <td>32</td>\n",
       "      <td>133</td>\n",
       "      <td>136</td>\n",
       "      <td>46</td>\n",
       "      <td>32</td>\n",
       "      <td>133</td>\n",
       "      <td>136</td>\n",
       "      <td>46</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>44</td>\n",
       "      <td>34</td>\n",
       "      <td>129</td>\n",
       "      <td>140</td>\n",
       "      <td>44</td>\n",
       "      <td>34</td>\n",
       "      <td>124</td>\n",
       "      <td>136</td>\n",
       "      <td>cotton crop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>89</td>\n",
       "      <td>102</td>\n",
       "      <td>110</td>\n",
       "      <td>87</td>\n",
       "      <td>93</td>\n",
       "      <td>106</td>\n",
       "      <td>114</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>107</td>\n",
       "      <td>113</td>\n",
       "      <td>88</td>\n",
       "      <td>grey soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>49</td>\n",
       "      <td>77</td>\n",
       "      <td>93</td>\n",
       "      <td>75</td>\n",
       "      <td>46</td>\n",
       "      <td>66</td>\n",
       "      <td>86</td>\n",
       "      <td>72</td>\n",
       "      <td>49</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>73</td>\n",
       "      <td>90</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>73</td>\n",
       "      <td>94</td>\n",
       "      <td>79</td>\n",
       "      <td>red soil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_1_1  pixel_1_2  pixel_1_3  pixel_1_4  pixel_2_1  pixel_2_2  \\\n",
       "2893         67         81         86         64         67         81   \n",
       "43           80         94        102         83         76         89   \n",
       "942          46         32        133        136         46         32   \n",
       "349          89        102        110         87         93        106   \n",
       "4204         49         77         93         75         46         66   \n",
       "\n",
       "      pixel_2_3  pixel_2_4  pixel_3_1  pixel_3_2  ...  pixel_7_4  pixel_8_1  \\\n",
       "2893         82         64         67         77  ...         65         68   \n",
       "43           98         79         68         77  ...         83         79   \n",
       "942         133        136         46         32  ...        140         44   \n",
       "349         114         90         93        111  ...         88         88   \n",
       "4204         86         72         49         70  ...         76         50   \n",
       "\n",
       "      pixel_8_2  pixel_8_3  pixel_8_4  pixel_9_1  pixel_9_2  pixel_9_3  \\\n",
       "2893         77         86         65         72         81         86   \n",
       "43           91        104         79         75         79         96   \n",
       "942          34        129        140         44         34        124   \n",
       "349         107        118         88         88        107        113   \n",
       "4204         73         90         76         50         73         94   \n",
       "\n",
       "      pixel_9_4                         label  \n",
       "2893         68           very damp grey soil  \n",
       "43           79  soil with vegetation stubble  \n",
       "942         136                   cotton crop  \n",
       "349          88                     grey soil  \n",
       "4204         79                      red soil  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace label numbers with their names\n",
    "landsat_train.replace({'label' : landsat_labels_dict}, inplace=True)\n",
    "landsat_train.sample(n=5, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-premium",
   "metadata": {},
   "source": [
    "Finally, we would like to store the features and the labels in two different `numpy` arrays. For that, will use the following two methods:\n",
    "* the `pandas` `drop()` method to remove columns or rows from a DataFrame ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)). We will use it to drop the `label` column.\n",
    "* the `to_numpy` method to transform a DataFrame into float64 numpy array ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_numpy.html)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "different-france",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of X: (4435, 36)\n",
      "Dimensionality of y: (4435,)\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "X = landsat_train.drop('label', axis=1).to_numpy(dtype='float64') # Input features\n",
    "y = landsat_train['label'].to_numpy()  # Labels\n",
    "print('Dimensionality of X: {}\\nDimensionality of y: {}'.format(X.shape, y.shape))\n",
    "\n",
    "print(type(X[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-decrease",
   "metadata": {},
   "source": [
    "## Question 2: feature standardisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-michigan",
   "metadata": {},
   "source": [
    "Feature standardisation is a pre-processing technique that is often used to transform data so that the variables/features are standardised to have the same location and scale. For many algorithms, this is a very important step for training models (both in the context of regression and classification). Read about feature standardisation in the lecture notes and e.g. [here](http://scikit-learn.org/stable/modules/preprocessing.html). \n",
    "\n",
    "Scikit-learn offers an [implementation](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) of feature standardisation. Machine learning methods in scikit-learn are implemented as `estimators` with a uniform API (see the [documentation](https://scikit-learn.org/stable/developers/develop.html), optional reading). All estimators implement a `fit` method to learn from data. Classes for supervised learning further provide the `predict` method which predicts outputs (labels) from inputs (e.g. the data matrix `X` above). Classes for unsupervised learning provide the `transform` method to transform the original data into an alternative representation. Sometimes, fitting and transforming can be done more efficiently together. In this case, the classes provide the `fit_transform` method.\n",
    "\n",
    "Create a `StandardScaler` and use it to fit and transform `X`. Save the results in a new array `X_sc`. Print the means and standard deviations (of the first 4 columns/features) of the original data `X` and the standardised data `X_sc` as a sanity check. \n",
    "\n",
    "**For the rest of this lab you should use the standardised data (i.e. `X_sc`), unless you are explicitly asked to do otherwise.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-conditions",
   "metadata": {},
   "source": [
    "## Question 3: visualisations\n",
    "In order to get a first idea about the data, we can use basic explorations and visualisations as those in lab 1. Below we will be using various dimensionality reduction methods to obtain (hopefully!) more informative visualisations in 2D. For your convenience, we provide the following function `scatter_2d_label()` to create a 2D scatter plot that also annotates the corresponding classes appropriately. Execute the following cell and make sure you understand what this function does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_2d_label(X_2d, y, ax=None, s=2, alpha=0.5, lw=2):\n",
    "    \"\"\"Visualise a 2D embedding with corresponding labels.\n",
    "    \n",
    "    X_2d : ndarray, shape (n_samples,2)\n",
    "        Low-dimensional feature representation.\n",
    "    \n",
    "    y : ndarray, shape (n_samples,)\n",
    "        Labels corresponding to the entries in X_2d.\n",
    "        \n",
    "    ax : matplotlib axes.Axes \n",
    "         axes to plot on\n",
    "         \n",
    "    s : float\n",
    "        Marker size for scatter plot.\n",
    "    \n",
    "    alpha : float\n",
    "        Transparency for scatter plot.\n",
    "        \n",
    "    lw : float\n",
    "        Linewidth for scatter plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    targets = np.unique(y)  # extract unique labels\n",
    "    colors = sns.color_palette(n_colors=targets.size)\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "    # scatter plot    \n",
    "    for color, target in zip(colors, targets):\n",
    "        ax.scatter(X_2d[y == target, 0], X_2d[y == target, 1], color=color, label=target, s=s, alpha=alpha, lw=lw)\n",
    "    \n",
    "    # add legend\n",
    "    ax.legend(loc='center left', bbox_to_anchor=[1.01, 0.5], scatterpoints=3, frameon=False); # Add a legend outside the plot at specified point\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-species",
   "metadata": {},
   "source": [
    "The following cell selects two columns of `X_sc` (i.e. features in the high-dimensional space) and uses the `scatter_2d_label()` function provided above to visualise the 2D scatter plots. Feel free to experiment with other dimensions too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_1 = 19 # First dimension\n",
    "dim_2 = 25 # Second dimension\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "scatter_2d_label(X_sc[:, [dim_1,dim_2]], y, ax=ax)\n",
    "ax.set(xlabel='Dim {}'.format(dim_1), ylabel= 'Dim {}'.format(dim_2));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-start",
   "metadata": {},
   "source": [
    "Plotting dimension 19 versus 25 shows that e.g. cotton crop takes on rather different values than the other classes even after standardisation, and hence should be easy to separate in a classification problem.\n",
    "\n",
    "An alternative to scatter plots are two-dimensional kernel density estimates. The function `kde_2d_label()` below produces a two-dimensional kernel density estimates separately for each class. Make sure to understand what each line does. \n",
    "\n",
    "Below we discuss in more detail the choice of the colour palette, i.e. the commands `sns.color_palette` and `sns.dark_palette` as they are used in many more contexts than kernel density estimation. If you would like to know more about the `mlines.Line2D([],[], ...)` command, see [here](https://matplotlib.org/3.3.3/tutorials/intermediate/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists) (optional reading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kde_2d_label(X_2d, y, ax=None):\n",
    "    \"\"\"Kernel density estimate in a 2D embedding with corresponding labels.\n",
    "    \n",
    "    X_2d : ndarray, shape (n_samples,2)\n",
    "        Data to plot\n",
    "    \n",
    "    y : ndarray, shape (n_samples,)\n",
    "        Labels corresponding to the entries in X_2d.\n",
    "        \n",
    "    ax : matplotlib axes.Axes \n",
    "         axes to plot on    \n",
    "    \"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "    targets = np.unique(y)\n",
    "    palette_name = 'bright'\n",
    "    colors = sns.color_palette(palette_name, n_colors=targets.size)\n",
    "    lines = []\n",
    "    for color, target in zip(colors, targets):\n",
    "        sns.kdeplot(X_2d[y==target, 0], X_2d[y==target, 1], ax=ax, cmap=sns.dark_palette(color, as_cmap=True))\n",
    "        lines.append(mlines.Line2D([], [], color=color, label=target))  # dummy line for the legend\n",
    "    \n",
    "    # add legend\n",
    "    ax.legend(lines, targets, loc='center left', bbox_to_anchor=[1.01, 0.5], frameon=False) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the scatter plot from above becomes\n",
    "kde_2d_label(X_sc[:, [dim_1,dim_2]], y)\n",
    "ax = plt.gca()\n",
    "ax.set(xlabel='Dim {}'.format(dim_1), ylabel= 'Dim {}'.format(dim_2));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-launch",
   "metadata": {},
   "source": [
    "With `sns.color_palette`, we can control the colours used to visualise the data. Have a quick look at its [documentation](https://seaborn.pydata.org/generated/seaborn.color_palette.html). The most important parameters are `palette` and `n_colors`, which specifies how many number of colours of the palette to use. The options for `palette` are a bit more complicated but it is worthwhile to understand the different kinds of palettes that are available. The explanations below are based on the seaborn tutorial [\"Choosing color palettes\"](https://seaborn.pydata.org/tutorial/color_palettes.html).\n",
    "\n",
    "An important guiding principle in choosing palettes is to use different hues (\"colors\", e.g. red or blue) to represent categories that do not have any ordering (e.g. the class labels above) while using variations in luminance/lightness to represent quantities with a natural ordering (e.g. numbers). Saturation of a colour can be used make different hues look more distinct.\n",
    "\n",
    "The available palettes can be classified into three categories:\n",
    "- qualitative palettes: these are used for categorical data. An example is `tab10` (slightly more intense than the default palette) or `Set2`.\n",
    "- sequential palettes: these are appropriate when data have a natural ordering and range from relatively low or uninteresting values to relatively high or interesting values (or vice versa). An example is `viridis`. Note that every continuous colormap has a reversed version, which has the suffix \"_r\", e.g. `viridis_r`.  \n",
    "- diverging palettes: these are best suited for datasets where both the low and high values are of equal interest while the midpoint should be deemphasised. This can be used to visualise extreme events such as hot and cold temperatures. An example is `vlag`.\n",
    "\n",
    "The default palette that you get with `palette=None` is of the qualitative type. Seaborn offers six variations of the default that have different levels of luminance and saturations. You can set them by choosing one of the following values for the `palette` parameter:  `deep`, `muted`, `pastel`, `bright`, `dark`, `colorblind`.  The tutorial has a [helpful figure](https://seaborn.pydata.org/tutorial/color_palettes.html#qualitative-color-palettes) that shows the resulting colormaps along the saturation and luminance \"dimensions\". [This page](https://gist.github.com/mwaskom/b35f6ebc2d4b340b4f64a4e28e778486) visualises how the different palettes appear for people with various color vision deficiencies. \n",
    "\n",
    "In the code above, we also use `sns.dark_palette(color, as_cmap=True)`. This, and its counterpart `light_palette` can be used to generate custom sequential palettes that start with either dark or light values and smoothly ramp up to the target specified as `color`. This allows us to visualise the values of the kernel density estimate with the same hue that we used to represent the category.\n",
    "\n",
    "Finally, note that with `as_cmap` we control the type of the return value: RGB values (`as_cmap=False`) or matplotlib colormaps  (`as_cmap=True`).\n",
    "\n",
    "Use the piece of code below to experiment with different colour palettes. You can use `plt.colormaps()` to get a (long) list of matplotlib colourmaps and/or have a look at its [documentation](https://matplotlib.org/api/pyplot_summary.html?highlight=colormaps#matplotlib.pyplot.colormaps). A further great resource for colour palettes is the [Color Brewer](https://colorbrewer2.org/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.unique(y)\n",
    "\n",
    "# for example\n",
    "palette_names = [None, 'tab10', 'dark', 'viridis', 'viridis_r', 'vlag', 'PuOr', 'gnuplot2']\n",
    "\n",
    "for i, palette in enumerate(palette_names):\n",
    "    colors = sns.color_palette(palette, n_colors=targets.size)\n",
    "    sns.palplot(colors)\n",
    "    plt.title('Palette name: ' + str(palette))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-proportion",
   "metadata": {},
   "source": [
    "# Linear dimensionality reduction by PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-lodging",
   "metadata": {},
   "source": [
    "In Lab 2, we implemented principal component analysis (PCA) from scratch and have seen how to [perform PCA with scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). We will use it here for (linear) dimensionality reduction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-brooks",
   "metadata": {},
   "source": [
    "## Question 4: computing the PC scores\n",
    "Use scikit-learn to compute the first two PC scores from the (standardised) input data and visualise the lower-dimensional representation with `scatter_2d_label` or `kde_2d_label`. Interpret the learned representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-doctor",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-robertson",
   "metadata": {},
   "source": [
    "# Dimensionality reduction by kernel PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-prime",
   "metadata": {},
   "source": [
    "In PCA, the lower dimensional representation is obtained by linear projections and this can severely limit the usefulness of the approach. Several versions of nonlinear PCA have been proposed in the hope of overcoming this problem. One such algorithm is kernel PCA (KPCA).\n",
    "\n",
    "Kernel PCA uses the  \"kernel trick\" to create a nonlinear version of PCA in sample space by performing ordinary PCA in the augmented kernel space. Scikit-learn offers an implementation of KPCA that supports various kernels.  Familiarise yourself with the `KernelPCA` class  by reading the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html#sklearn.decomposition.KernelPCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-citizenship",
   "metadata": {},
   "source": [
    "## Question 5: effect of the kernel\n",
    "\n",
    "Apply kernel PCA to the standardised data `X_sc`. Set the `n_components` parameter to `2` and use default settings for other parameters. Experiment with different kernels. How do the results differ when different kernels are used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-representation",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-university",
   "metadata": {},
   "source": [
    "## Question 6: effect of standardisation\n",
    "\n",
    "Apply kernel PCA with a RBF kernel to:\n",
    "1. the raw data in `X`\n",
    "2. the standardised data in `X_sc`. \n",
    "\n",
    "What do you observe? Can you explain the outcome?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-selection",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-wesley",
   "metadata": {},
   "source": [
    "# Multidimensional scaling (MDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-helmet",
   "metadata": {},
   "source": [
    "Multidimensional scaling (MDS) refers to a collection of techniques for dimensionality reduction that operate on dissimilarities. The goal of MDS is to find a configuration of points in the plane, or more generally the Euclidean space, so that their distances well represent the original dissimilarities.\n",
    "\n",
    "We look here into metric MDS (see Section 3.3.1 in the lecture notes). Scikit-learn offers an implementation.  Familiarise yourself with the class `MDS` by reading the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.MDS.html). Note that with the default settings, Euclidean distances between the input data are used to obtain the pairwise dissimilarities $\\delta_{ij}$ from the lecture notes. However, a major strength of MDS is that it operates on dissimilarities directly, and does not require access to data. If you want to operate on dissimilarities, you can to specify `dissimilarity='precomputed'` and feed the corresponding dissimilarity matrix to `fit` or `fit_transform`.\n",
    "\n",
    "The attribute `stress_` corresponds to the minimal value of the loss function minimised in MDS (smaller values are better). Note: The stress does not seem to be correctly defined in the [user guide](https://scikit-learn.org/stable/modules/manifold.html#multidimensional-scaling) (weights and the squaring are missing) but the loss used in the code is the same as the lecture notes (up to a factor 1/2 it seems)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-heath",
   "metadata": {},
   "source": [
    "## Question 7: MDS based on Euclidean distances\n",
    "Compute a two-dimensional representation of the standardised data `X_sc` via scikit-learn using Euclidean distances between the original data points to define the dissimilarities. If the default settings result in too long compute times, you can e.g. reduce `max_iter` to `100` and/or `n_init` to `1`. You can parallelise computations using the `n_jobs` parameter.\n",
    "\n",
    "Visualise the data by using the `scatter_2d_label()` function. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-friendly",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-wagon",
   "metadata": {},
   "source": [
    "## Question 8: MDS based on custom distances\n",
    "\n",
    "We now apply MDS to a dissimilarity matrix directly. You can define your own dissimilarities to obtain the matrix, or you can also make use of distances that are already implemented in skit-learn or scipy via the `pairwise_distances` function (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html)).\n",
    "\n",
    "Perform here MDS with the `braycurtis` or `canberra` dissimilarity available through `pairwise_distances` and interpret the results. The Bray-Curtis dissimilarity is used in ecology and the environmental sciences (see e.g. [here](http://www.econ.upf.edu/~michael/stanford/maeb5.pdf), optional reading). The Canberra dissimilarity is a weighted $L_1$ distance (see e.g. [here](https://en.wikipedia.org/wiki/Canberra_distance)). For their exact definitions, see [here](https://docs.scipy.org/doc/scipy/reference/spatial.distance.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# Your code goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-copyright",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-kuwait",
   "metadata": {},
   "source": [
    "#  Isomap\n",
    "MDS does not attempt to explicitly model the underlying data manifold. Isomap, on the other hand, addresses the dimensionality reduction problem by doing so. Suppose your data lie on a curve, but the curve is not a straight line. The key assumption made by Isomap is that the quantity of interest, when comparing two points, is the distance along the curve between the two points. \n",
    "\n",
    "In other words, Isomap performs MDS in the geodesic space of the nonlinear data manifold. The geodesic distances represent the shortest paths along the curved surface of the manifold measured as if the surface was flat. This can be approximated by a sequence of short steps between neighbouring sample points. Isomap then applies classical MDS to the geodesic rather than straight line distances to find a low-dimensional mapping that preserves these pairwise distances.\n",
    "\n",
    "To summarise, Isomap uses three steps:\n",
    "1.  Find the neighbours of each data point in high-dimensional data\n",
    "2.  Compute the geodesic pairwise distances between all points\n",
    "3.  Embed the data via classical MDS so as to preserve these distances.\n",
    "\n",
    "\n",
    "Familiarise yourself with the Isomap class in scikit-learn by reading the [user guide](http://scikit-learn.org/stable/modules/manifold.html#isomap) and  [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.Isomap.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-weekend",
   "metadata": {},
   "source": [
    "## Question 9: influence of the neighbourhood\n",
    "\n",
    "Project the standardised data into a 2D space via the Isomap algorithm. Explore the role of the `n_neighbors` parameter which defines how many neighbours are used in step 1 above. You can start by trying the following values, but feel free to experiment further: [2, 3, 5, 10]. How sensitive is the algorithm to the choice of `n_neighbors`?\n",
    "\n",
    "Use default settings for other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "\n",
    "# Your code goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-drunk",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-survey",
   "metadata": {},
   "source": [
    "#  Other methods for dimensionality reduction [optional reading]\n",
    "\n",
    "We here briefly mention two other methods that are widely used and point to code implementing them: \n",
    "\n",
    "* Uniform Manifold Approximation and Projection (UMAP)\n",
    "* t-distributed Stochastic Neighbor (t-SNE) Embedding\n",
    "\n",
    "UMAP is discussed in the lecture notes. Code that follows the scikit-learn API is available here [here](https://github.com/lmcinnes/umap), and the documentation [here](https://umap-learn.readthedocs.io/en/latest/).\n",
    "\n",
    "t-SNE is a powerful tool to visualize high-dimensional data. It converts similarities between data points to joint probabilities and tries to minimize the Kullback-Leibler divergence between the joint probabilities of the low-dimensional embedding and the high-dimensional data. scikit-learn has an implementation ([documentation](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)). The following webpage provides an excellent interactive introduction to t-SNE that also allows you to see the impact of its different hyperparameters: http://distill.pub/2016/misread-tsne/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "313.317px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
